---
title: "Business Analytics"
mainfont: NanumGothic
output:
  pdf_document: null
  latex_engine: pdfLaTex
  word_document: default
  html_document:
    df_print: paged
header-includes: 
  \usepackage{kotex}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(tinytex.verbose = TRUE)
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)
library(dplyr)
library(stringr)
library(tidyverse)
library(ggplot2)
library(forecast)
```

## \textcolor{blue}{1장, 2장. 데이터 마이닝 프로세스 개요 - West Roxbury 데이터셋을 활용}

```{r}
# Loading data
housing.df <- read.csv('https://raw.githubusercontent.com/reisanar/datasets/master/WestRoxbury.csv')
dim(housing.df)
```


```{r}
# Random sample of 5 observations
housing.df[sample(row.names(housing.df), 5), ]

# Oversample houses with over 10 rooms
s <- sample(row.names(housing.df), 5, prob = ifelse(housing.df$ROOMS > 10, 0.9, 0.01))
housing.df[s, ]
```

분류하고자 하는 데이터가 희귀할 경우에는 이를 처리할 수 있도록 해줘야 한다.

이를 하는 방법은 소수 사건에 가중치를 부여하거나, 오분류에 큰 가중치를 주는 방법이 있다.

```{r}
# Categorical variables -> Dummy variables
xtotal <- model.matrix(~ 0 + BEDROOMS + REMODEL, data = housing.df)
xtotal <- as.data.frame(xtotal)
t(t(names(xtotal)))
xtotal <- xtotal[, -4]
head(xtotal, 5)
```

범주의 순서가 없는 Categorical variables의 값들은 가변수를 만들어주는 Dummy coding이 가능하다.

```{r}
# Median 값으로 결측치 대체하기
rows.to.missing <- sample(row.names(housing.df), 10)
housing.df[rows.to.missing, ]$BEDROOMS <- NA
summary(housing.df$BEDROOMS)

housing.df[rows.to.missing, ]$BEDROOMS <- median(housing.df$BEDROOMS, na.rm = TRUE)
summary(housing.df$BEDROOMS)
```

```{r}
set.seed(1)

# Train, valid dataset split
train.rows <- sample(rownames(housing.df), dim(housing.df)[1] * 0.6)
train.data <- housing.df[train.rows, ]
valid.rows <- setdiff(rownames(housing.df), train.rows)
valid.data <- housing.df[valid.rows, ]

# Train, valid, test = 50%, 30%, 20%
train.rows <- sample(rownames(housing.df), dim(housing.df)[1] * 0.5)
valid.rows <- sample(setdiff(rownames(housing.df), train.rows), 
                     dim(housing.df)[1] * 0.3)
test.rows <- setdiff(rownames(housing.df), union(train.rows, valid.rows))

train.data <- housing.df[train.rows, ]
valid.data <- housing.df[valid.rows, ]
test.data <- housing.df[test.rows, ]

dim(train.data)
dim(valid.data)
dim(test.data)
```

모델을 구축하기 위해서 데이터셋을 Train, Valid, Test로 나눠주도록 한다.

일반적으로 모델링 과정은 다음과 같은 순서를 갖는다.

#### 데이터 마이닝 모델링 process

1. [목적] 웨스트 록스베리 지역 주택 가격을 예측한다.
2. [데이터 획득] 주택 가격 데이터를 활용한다.
3. [데이터 탐색, 정제, 전처리] 변수에 대한 충분한 이해를 한다.
    - 어떤 변수를 사용할 것인가
    - 이상치 유무를 확인
    - 범주형 변수를 가변수로 변환 (Dummy coding)
4. [차원 축소] 많은 변수를 갖는 경우에는, 차원 축소 방법을 사용한다.
5. [데이터 마이닝 태스크 결정] 주택 가격 예측을 위한 지도학습 방법을 사용한다.
6. [지도학습을 위해 데이터 분할] Train, Valid, Test 데이터로 나눈다.
7. [데이터 마이닝 기법 선택] 이번 분석에서는 다중회귀분석을 사용한다.
8. [태스크를 위한 알고리즘 사용] 모델 평가 지표를 만든다.
9. [결과 해석] 다양한 방법을 통해 나온 결과들 중 가장 좋은 모델을 선택한다.
10. [모델 사용] 최상의 모델에 대해서 목표한 바에 대한 결과를 얻는다.

```{r}
# Modeling
reg <- lm(TOTAL.VALUE ~ ., data = housing.df, subset = train.rows)
tr.res <- data.frame(train.data$TOTAL.VALUE, reg$fitted.values, reg$residuals)
head(tr.res)
```

\pagebreak

```{r}
# 만들어진 모델을 Valid 데이터에 적용하기
pred <- predict(reg, newdata = valid.data)
vl.res <- data.frame(valid.data$TOTAL.VALUE, pred, 
                     residuals = valid.data$TOTAL.VALUE - pred)
head(vl.res)
```

```{r}
# 모델의 평가 측도를 계산
accuracy(reg$fitted.values, train.data$TOTAL.VALUE) # train data
pred <- predict(reg, newdata = valid.data)
accuracy(pred, valid.data$TOTAL.VALUE)
```

\pagebreak

## \textcolor{blue}{5장. 예측 성능 평가}

#### 지도학습의 출력 변수

1. 예측된 수치값: 출력 변수가 주택 가격과 같은 수치값
2. 예측된 클래스 소속도: 출력 변수가 범주값
    - 경향의 컷오프(Threshold) 값을 사용하여 클래스 소속도 생성
3. 경향: 출력 변수가 범주값 일 때의 클래스 소속도의 확률

